{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "eaea1908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e0f304cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SONY\\Desktop\\data\\Pulse\\data\n"
     ]
    }
   ],
   "source": [
    "repo_url = \"https://github.com/PhonePe/pulse.git\"\n",
    "clone_path = r\"C:\\Users\\SONY\\Desktop\\data\"\n",
    "\n",
    "if not os.path.exists(clone_path):\n",
    "    os.makedirs(clone_path)\n",
    "\n",
    "repo_path = os.path.join(clone_path, os.path.basename(repo_url).removesuffix('.git').title())\n",
    "\n",
    "Repo.clone_from(repo_url, repo_path)\n",
    "\n",
    "dir1 = os.path.join(repo_path, 'data')\n",
    "print(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "33db919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(dir1):\n",
    "    for root, dirs, files in os.walk(dir1):\n",
    "        if 'state' in dirs:\n",
    "            state_dir = os.path.join(root, 'state')\n",
    "            for state_folder in os.listdir(state_dir):\n",
    "                # rename the state folder\n",
    "                old_path = os.path.join(state_dir, state_folder)\n",
    "                new_path = os.path.join(state_dir, state_folder.title().replace('-', ' ').replace('&', 'and'))\n",
    "                os.rename(old_path, new_path)\n",
    "    print(\"Renamed all sub-directories successfully\")\n",
    "                \n",
    "# Function to extract all paths that has sub-directory in the name of 'state'\n",
    "\n",
    "def extract_paths(dir1):\n",
    "    path_list = []\n",
    "    for root, dirs, files in os.walk(dir1):\n",
    "        if os.path.basename(root) == 'state':\n",
    "            path_list.append(root.replace('\\\\', '/'))\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1ad97089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/SONY/Desktop/data/Pulse/data/aggregated/transaction/country/india/state',\n",
       " 'C:/Users/SONY/Desktop/data/Pulse/data/aggregated/user/country/india/state',\n",
       " 'C:/Users/SONY/Desktop/data/Pulse/data/map/transaction/hover/country/india/state',\n",
       " 'C:/Users/SONY/Desktop/data/Pulse/data/map/user/hover/country/india/state',\n",
       " 'C:/Users/SONY/Desktop/data/Pulse/data/top/transaction/country/india/state',\n",
       " 'C:/Users/SONY/Desktop/data/Pulse/data/top/user/country/india/state']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dir1 = extract_paths(dir1)\n",
    "state_dir1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2cd26d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggerate_transaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5276e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_dir1[0]\n",
    "state_list = os.listdir(state_path)\n",
    "agg_trans_dict = {\n",
    "    'State': [], 'Year': [], 'Transaction_type': [],\n",
    "    'Transaction_count': [], 'Transaction_amount': []\n",
    "}\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "\n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "\n",
    "            try:\n",
    "                for transaction_data in df['data']['transactionData']:\n",
    "                    type = transaction_data['name']\n",
    "                    count = transaction_data['paymentInstruments'][0]['count']\n",
    "                    amount = transaction_data['paymentInstruments'][0]['amount']\n",
    "\n",
    "                    # Appending to agg_trans_dict\n",
    "                    agg_trans_dict['State'].append(state)\n",
    "                    agg_trans_dict['Year'].append(year)\n",
    "                    agg_trans_dict['Transaction_type'].append(type)\n",
    "                    agg_trans_dict['Transaction_count'].append(count)\n",
    "                    agg_trans_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "agg_trans_df = pd.DataFrame(agg_trans_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c376d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggerate_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f178a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_dir1[1]\n",
    "state_list = os.listdir(state_path)\n",
    "agg_user_dict = {\n",
    "    'State': [], 'Year': [], 'Transaction_count': [], 'Percentage': []\n",
    "}\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "\n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "\n",
    "            try:\n",
    "                for user_data in df['data']['usersByDevice']:\n",
    "                    count = user_data['count']\n",
    "                    percent = user_data['percentage']\n",
    "\n",
    "                    # Appending to agg_user_dict\n",
    "                    agg_user_dict['State'].append(state)\n",
    "                    agg_user_dict['Year'].append(year)\n",
    "                    agg_user_dict['Transaction_count'].append(count)\n",
    "                    agg_user_dict['Percentage'].append(percent)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "agg_user_df = pd.DataFrame(agg_user_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0461f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "beaa1c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_dir1[2]\n",
    "state_list = os.listdir(state_path)\n",
    "map_trans_dict = {\n",
    "    'State': [], 'Year': [], 'District': [],\n",
    "    'Transaction_count': [], 'Transaction_amount': []\n",
    "}\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "\n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "\n",
    "            try:\n",
    "                for transaction_data in df['data']['hoverDataList']:\n",
    "                    district = transaction_data['name']\n",
    "                    count = transaction_data['metric'][0]['count']\n",
    "                    amount = transaction_data['metric'][0]['amount']\n",
    "\n",
    "                    # Appending to map_trans_dict\n",
    "                    map_trans_dict['State'].append(state)\n",
    "                    map_trans_dict['Year'].append(year)\n",
    "                    map_trans_dict['District'].append(district.removesuffix(' district').title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    map_trans_dict['Transaction_count'].append(count)\n",
    "                    map_trans_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "map_trans_df = pd.DataFrame(map_trans_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9ba4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5406d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_dir1[3]\n",
    "state_list = os.listdir(state_path)\n",
    "map_user_dict = {\n",
    "    'State': [], 'Year': [], 'District': [],\n",
    "    'Registered_users': [], 'App_opens': []\n",
    "}\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "\n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "\n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "\n",
    "            try:\n",
    "                for district, user_data in df['data']['hoverData'].items():\n",
    "                    reg_user_count = user_data['registeredUsers']\n",
    "                    app_open_count = user_data['appOpens']\n",
    "\n",
    "                    # Appending to map_user_dict\n",
    "                    map_user_dict['State'].append(state)\n",
    "                    map_user_dict['Year'].append(year)\n",
    "                    map_user_dict['District'].append(district.removesuffix(' district').title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    map_user_dict['Registered_users'].append(reg_user_count)\n",
    "                    map_user_dict['App_opens'].append(app_open_count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "map_user_df = pd.DataFrame(map_user_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19874127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction distrct wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3bd0773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_dir1[4]\n",
    "state_list = os.listdir(state_path)\n",
    "top_trans_dist_dict = {\n",
    "                        'State': [], 'Year': [], 'District': [],\n",
    "                        'Transaction_count': [], 'Transaction_amount': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for district_data in df['data']['districts']:\n",
    "                    \n",
    "                    name = district_data['entityName']\n",
    "                    count = district_data['metric']['count']\n",
    "                    amount = district_data['metric']['amount']\n",
    "                    # Appending to top_trans_dist_dict\n",
    "                    \n",
    "                    top_trans_dist_dict['State'].append(state)\n",
    "                    top_trans_dist_dict['Year'].append(year)\n",
    "                    top_trans_dist_dict['District'].append(name.title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    top_trans_dist_dict['Transaction_count'].append(count)\n",
    "                    top_trans_dist_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_trans_dist_df = pd.DataFrame(top_trans_dist_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a83ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "680fe60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_dir1[5]\n",
    "state_list = os.listdir(state_path)\n",
    "top_user_dist_dict = {\n",
    "                        'State': [], 'Year': [], 'District': [],\n",
    "                        'Registered_users': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for district_data in df['data']['districts']:\n",
    "                    \n",
    "                    name = district_data['name']\n",
    "                    count = district_data['registeredUsers']\n",
    "                    # Appending to top_user_dist_dict\n",
    "                    \n",
    "                    top_user_dist_dict['State'].append(state)\n",
    "                    top_user_dist_dict['Year'].append(year)\n",
    "                    top_user_dist_dict['District'].append(name.title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    top_user_dist_dict['Registered_users'].append(count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_user_dist_df = pd.DataFrame(top_user_dist_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d599d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e023dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agg_trans_df',\n",
       " 'agg_user_df',\n",
       " 'map_trans_df',\n",
       " 'map_user_df',\n",
       " 'top_trans_dist_df',\n",
       " 'top_user_dist_df']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [df for df in globals() if isinstance(globals()[df], pd.core.frame.DataFrame) and df.endswith('_df')]\n",
    "\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf915d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some mismatch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6964e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding Latitude and Longitude columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9b8aed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long_df = pd.read_csv(r\"C:\\Users\\SONY\\Downloads\\dist_lat_long.csv\")\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    if 'district' in df.columns:\n",
    "        df = pd.merge(df, lat_long_df, on=['state', 'district'], how='left')\n",
    "        globals()[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f331d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_region_column(df):\n",
    "    state_groups = {\n",
    "        'Northern Region': ['Jammu and Kashmir', 'Himachal Pradesh', 'Punjab', 'Chandigarh', 'Uttarakhand', 'Ladakh', 'Delhi', 'Haryana'],\n",
    "        'Central Region': ['Uttar Pradesh', 'Madhya Pradesh', 'Chhattisgarh'],\n",
    "        'Western Region': ['Rajasthan', 'Gujarat', 'Dadra and Nagar Haveli and Daman and Diu', 'Maharashtra'],\n",
    "        'Eastern Region': ['Bihar', 'Jharkhand', 'Odisha', 'West Bengal', 'Sikkim'],\n",
    "        'Southern Region': ['Andhra Pradesh', 'Telangana', 'Karnataka', 'Kerala', 'Tamil Nadu', 'Puducherry', 'Goa', 'Lakshadweep', 'Andaman and Nicobar Islands'],\n",
    "        'North-Eastern Region': ['Assam', 'Meghalaya', 'Manipur', 'Nagaland', 'Tripura', 'Arunachal Pradesh', 'Mizoram']\n",
    "    }\n",
    "    \n",
    "    df['Region'] = df['State'].map({state: region for region, states in state_groups.items() for state in states})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3a4eb3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>District</th>\n",
       "      <th>Transaction_count</th>\n",
       "      <th>Transaction_amount</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andamannicobarislands</td>\n",
       "      <td>2018</td>\n",
       "      <td>North and Middle Andaman</td>\n",
       "      <td>442</td>\n",
       "      <td>9.316631e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andamannicobarislands</td>\n",
       "      <td>2018</td>\n",
       "      <td>South Andaman</td>\n",
       "      <td>5688</td>\n",
       "      <td>1.256025e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andamannicobarislands</td>\n",
       "      <td>2018</td>\n",
       "      <td>Nicobars</td>\n",
       "      <td>528</td>\n",
       "      <td>1.139849e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andamannicobarislands</td>\n",
       "      <td>2018</td>\n",
       "      <td>North and Middle Andaman</td>\n",
       "      <td>825</td>\n",
       "      <td>1.317863e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andamannicobarislands</td>\n",
       "      <td>2018</td>\n",
       "      <td>South Andaman</td>\n",
       "      <td>9395</td>\n",
       "      <td>2.394824e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14631</th>\n",
       "      <td>westbengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>Nadia</td>\n",
       "      <td>12690126</td>\n",
       "      <td>2.804568e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14632</th>\n",
       "      <td>westbengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>Birbhum</td>\n",
       "      <td>7617444</td>\n",
       "      <td>1.614650e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>westbengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>Purba Medinipur</td>\n",
       "      <td>14484229</td>\n",
       "      <td>3.309949e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>westbengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>Maldah</td>\n",
       "      <td>12492746</td>\n",
       "      <td>2.721861e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>westbengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>Darjiling</td>\n",
       "      <td>8827502</td>\n",
       "      <td>1.801650e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14636 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       State  Year                  District   \n",
       "0      andamannicobarislands  2018  North and Middle Andaman  \\\n",
       "1      andamannicobarislands  2018             South Andaman   \n",
       "2      andamannicobarislands  2018                  Nicobars   \n",
       "3      andamannicobarislands  2018  North and Middle Andaman   \n",
       "4      andamannicobarislands  2018             South Andaman   \n",
       "...                      ...   ...                       ...   \n",
       "14631             westbengal  2022                     Nadia   \n",
       "14632             westbengal  2022                   Birbhum   \n",
       "14633             westbengal  2022           Purba Medinipur   \n",
       "14634             westbengal  2022                    Maldah   \n",
       "14635             westbengal  2022                 Darjiling   \n",
       "\n",
       "       Transaction_count  Transaction_amount  Latitude  Longitude  \n",
       "0                    442        9.316631e+05       NaN        NaN  \n",
       "1                   5688        1.256025e+07       NaN        NaN  \n",
       "2                    528        1.139849e+06       NaN        NaN  \n",
       "3                    825        1.317863e+06       NaN        NaN  \n",
       "4                   9395        2.394824e+07       NaN        NaN  \n",
       "...                  ...                 ...       ...        ...  \n",
       "14631           12690126        2.804568e+10       NaN        NaN  \n",
       "14632            7617444        1.614650e+10       NaN        NaN  \n",
       "14633           14484229        3.309949e+10       NaN        NaN  \n",
       "14634           12492746        2.721861e+10       NaN        NaN  \n",
       "14635            8827502        1.801650e+10       NaN        NaN  \n",
       "\n",
       "[14636 rows x 7 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Normalize state names in lat_long_df\n",
    "lat_long_df['State'] = lat_long_df['State'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x.lower()))\n",
    "\n",
    "# Normalize state names in existing_df\n",
    "map_trans_df['State'] = map_trans_df['State'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x.lower()))\n",
    "\n",
    "# Merge the 'Latitude' and 'Longitude' columns from lat_long_df to existing_df\n",
    "map_trans_df = map_trans_df.merge(lat_long_df[['State', 'District', 'Latitude', 'Longitude']], on=['State', 'District'], how='left')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "map_trans_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3b3e797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_trans_df = map_trans_df.drop('Longitude', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b953071d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>district</th>\n",
       "      <th>transaction_count</th>\n",
       "      <th>transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>andamannicobarislands</td>\n",
       "      <td>2018</td>\n",
       "      <td>north and middle andaman</td>\n",
       "      <td>442</td>\n",
       "      <td>9.316631e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andamannicobarislands</td>\n",
       "      <td>2018</td>\n",
       "      <td>south andaman</td>\n",
       "      <td>5688</td>\n",
       "      <td>1.256025e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andamannicobarislands</td>\n",
       "      <td>2018</td>\n",
       "      <td>nicobars</td>\n",
       "      <td>528</td>\n",
       "      <td>1.139849e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andamannicobarislands</td>\n",
       "      <td>2018</td>\n",
       "      <td>north and middle andaman</td>\n",
       "      <td>825</td>\n",
       "      <td>1.317863e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andamannicobarislands</td>\n",
       "      <td>2018</td>\n",
       "      <td>south andaman</td>\n",
       "      <td>9395</td>\n",
       "      <td>2.394824e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14631</th>\n",
       "      <td>westbengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>nadia</td>\n",
       "      <td>12690126</td>\n",
       "      <td>2.804568e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14632</th>\n",
       "      <td>westbengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>birbhum</td>\n",
       "      <td>7617444</td>\n",
       "      <td>1.614650e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>westbengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>purba medinipur</td>\n",
       "      <td>14484229</td>\n",
       "      <td>3.309949e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>westbengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>maldah</td>\n",
       "      <td>12492746</td>\n",
       "      <td>2.721861e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>westbengal</td>\n",
       "      <td>2022</td>\n",
       "      <td>darjiling</td>\n",
       "      <td>8827502</td>\n",
       "      <td>1.801650e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14636 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       state  year                  district   \n",
       "0      andamannicobarislands  2018  north and middle andaman  \\\n",
       "1      andamannicobarislands  2018             south andaman   \n",
       "2      andamannicobarislands  2018                  nicobars   \n",
       "3      andamannicobarislands  2018  north and middle andaman   \n",
       "4      andamannicobarislands  2018             south andaman   \n",
       "...                      ...   ...                       ...   \n",
       "14631             westbengal  2022                     nadia   \n",
       "14632             westbengal  2022                   birbhum   \n",
       "14633             westbengal  2022           purba medinipur   \n",
       "14634             westbengal  2022                    maldah   \n",
       "14635             westbengal  2022                 darjiling   \n",
       "\n",
       "       transaction_count  transaction_amount  \n",
       "0                    442        9.316631e+05  \n",
       "1                   5688        1.256025e+07  \n",
       "2                    528        1.139849e+06  \n",
       "3                    825        1.317863e+06  \n",
       "4                   9395        2.394824e+07  \n",
       "...                  ...                 ...  \n",
       "14631           12690126        2.804568e+10  \n",
       "14632            7617444        1.614650e+10  \n",
       "14633           14484229        3.309949e+10  \n",
       "14634           12492746        2.721861e+10  \n",
       "14635            8827502        1.801650e+10  \n",
       "\n",
       "[14636 rows x 5 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca85be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##all coumns same letter and symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ae33a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long_df['State'] = lat_long_df['State'].str.lower()\n",
    "lat_long_df['District'] = lat_long_df['District'].str.lower()\n",
    "df['State'] = df['State'].str.lower()\n",
    "df['District'] = df['District'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0934fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = ['agg_trans_df',\n",
    "           'agg_user_df',\n",
    "           'map_trans_df',\n",
    "           'map_user_df',\n",
    "           'top_trans_dist_df',\n",
    "           'top_user_dist_df']\n",
    "\n",
    "df_list = [df.lower() for df in df_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b5be90b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    df.rename(columns=lambda x: x.lower(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "698fc317",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long_df.columns = lat_long_df.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "71ec2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "        df = df.drop(['latitude', 'longitude'], axis=1)\n",
    "        globals()[df_name] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_region_column(df):\n",
    "    state_groups = {\n",
    "        'Northern Region': ['Jammu and Kashmir', 'Himachal Pradesh', 'Punjab', 'Chandigarh', 'Uttarakhand', 'Ladakh', 'Delhi', 'Haryana'],\n",
    "        'Central Region': ['Uttar Pradesh', 'Madhya Pradesh', 'Chhattisgarh'],\n",
    "        'Western Region': ['Rajasthan', 'Gujarat', 'Dadra and Nagar Haveli and Daman and Diu', 'Maharashtra'],\n",
    "        'Eastern Region': ['Bihar', 'Jharkhand', 'Odisha', 'West Bengal', 'Sikkim'],\n",
    "        'Southern Region': ['Andhra Pradesh', 'Telangana', 'Karnataka', 'Kerala', 'Tamil Nadu', 'Puducherry', 'Goa', 'Lakshadweep', 'Andaman and Nicobar Islands'],\n",
    "        'North-Eastern Region': ['Assam', 'Meghalaya', 'Manipur', 'Nagaland', 'Tripura', 'Arunachal Pradesh', 'Mizoram']\n",
    "    }\n",
    "    \n",
    "    df['Region'] = df['State'].map({state: region for region, states in state_groups.items() for state in states})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "92e654ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_region = add_region_column(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d5605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec135351",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    print(f\"{df_name}:\")\n",
    "    print(f\"Null count: \\n{df.isnull().sum()}\")\n",
    "    print(f\"Duplicated rows count: \\n{df.duplicated().sum()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dffbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DATAFRAME INFO:\\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    print(df_name + ':\\n')\n",
    "    df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e736377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outer layer of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "445447ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outliers(df):\n",
    "    outliers = {}\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        if col in ['Transaction_count', 'Transaction_amount']:\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            upper_bound = q3 + (1.5 * iqr)\n",
    "            lower_bound = q1 - (1.5 * iqr)\n",
    "            outliers[col] = len(df[(df[col] > upper_bound) | (df[col] < lower_bound)])\n",
    "        else:\n",
    "            continue\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "df6e51bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTLIER COUNT ACROSS DATAFRAMES:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('OUTLIER COUNT ACROSS DATAFRAMES:\\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    outliers = count_outliers(df)\n",
    "    if len(outliers) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        print(df_name, \":\\n\\n\", outliers, \"\\n\")\n",
    "        print(\"\\n\", 55 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec0f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mysql connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "0cdbb2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3334"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "# Establish a connection to the MySQL server\n",
    "# Replace 'username', 'password', 'hostname', 'database' with your MySQL credentials\n",
    "engine = sqlalchemy.create_engine('mysql+mysqlconnector://root:12345@localhost/phonepe')\n",
    "\n",
    "# Assuming you have a dataframe called 'df' that you want to store\n",
    "table_name = 'agg_trans_df'  # Replace with the desired table name\n",
    "\n",
    "# Store the dataframe in the MySQL database\n",
    "agg_trans_df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "9681f1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5660"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "# Establish a connection to the MySQL server\n",
    "# Replace 'username', 'password', 'hostname', 'database' with your MySQL credentials\n",
    "engine = sqlalchemy.create_engine('mysql+mysqlconnector://root:12345@localhost/phonepe')\n",
    "\n",
    "# Assuming you have a dataframe called 'df' that you want to store\n",
    "table_name = 'agg_user_df'  # Replace with the desired table name\n",
    "\n",
    "# Store the dataframe in the MySQL database\n",
    "agg_user_df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f7b8d730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14257"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "# Establish a connection to the MySQL server\n",
    "# Replace 'username', 'password', 'hostname', 'database' with your MySQL credentials\n",
    "engine = sqlalchemy.create_engine('mysql+mysqlconnector://root:12345@localhost/phonepe')\n",
    "\n",
    "# Assuming you have a dataframe called 'df' that you want to store\n",
    "table_name = 'map_trans_df'  # Replace with the desired table name\n",
    "\n",
    "# Store the dataframe in the MySQL database\n",
    "map_trans_df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "e01da7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14260"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "# Establish a connection to the MySQL server\n",
    "# Replace 'username', 'password', 'hostname', 'database' with your MySQL credentials\n",
    "engine = sqlalchemy.create_engine('mysql+mysqlconnector://root:12345@localhost/phonepe')\n",
    "\n",
    "# Assuming you have a dataframe called 'df' that you want to store\n",
    "table_name = 'map_user_df'  # Replace with the desired table name\n",
    "\n",
    "# Store the dataframe in the MySQL database\n",
    "map_user_df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "6aef597e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5856"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "# Establish a connection to the MySQL server\n",
    "# Replace 'username', 'password', 'hostname', 'database' with your MySQL credentials\n",
    "engine = sqlalchemy.create_engine('mysql+mysqlconnector://root:12345@localhost/phonepe')\n",
    "\n",
    "# Assuming you have a dataframe called 'df' that you want to store\n",
    "table_name = 'top_trans_dist_df'  # Replace with the desired table name\n",
    "\n",
    "# Store the dataframe in the MySQL database\n",
    "top_trans_dist_df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "2108b959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5700"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "# Establish a connection to the MySQL server\n",
    "# Replace 'username', 'password', 'hostname', 'database' with your MySQL credentials\n",
    "engine = sqlalchemy.create_engine('mysql+mysqlconnector://root:12345@localhost/phonepe')\n",
    "\n",
    "# Assuming you have a dataframe called 'df' that you want to store\n",
    "table_name = 'top_user_dist_df'  # Replace with the desired table name\n",
    "\n",
    "# Store the dataframe in the MySQL database\n",
    "top_user_dist_df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
